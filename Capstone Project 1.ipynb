{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af82de90",
   "metadata": {},
   "source": [
    "## YouTube Data Harvesting & Warehousing Using SQL, MongoDB & Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cbfb04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Using cached streamlit-1.26.0-py2.py3-none-any.whl (8.1 MB)\n",
      "Requirement already satisfied: requests<3,>=2.18 in e:\\anaconda\\lib\\site-packages (from streamlit) (2.28.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in e:\\anaconda\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Collecting pyarrow>=6.0\n",
      "  Downloading pyarrow-13.0.0-cp310-cp310-win_amd64.whl (24.3 MB)\n",
      "     ---------------------------------------- 24.3/24.3 MB 6.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in e:\\anaconda\\lib\\site-packages (from streamlit) (1.23.5)\n",
      "Collecting protobuf<5,>=3.20\n",
      "  Using cached protobuf-4.24.3-cp310-abi3-win_amd64.whl (430 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in e:\\anaconda\\lib\\site-packages (from streamlit) (6.1)\n",
      "Collecting pympler<2,>=0.9\n",
      "  Using cached Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "Collecting tenacity<9,>=8.1.0\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Collecting cachetools<6,>=4.0\n",
      "  Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7\n",
      "  Using cached GitPython-3.1.36-py3-none-any.whl (189 kB)\n",
      "Collecting altair<6,>=4.0\n",
      "  Using cached altair-5.1.1-py3-none-any.whl (520 kB)\n",
      "Collecting validators<1,>=0.2\n",
      "  Using cached validators-0.22.0-py3-none-any.whl (26 kB)\n",
      "Collecting rich<14,>=10.14.0\n",
      "  Using cached rich-13.5.2-py3-none-any.whl (239 kB)\n",
      "Collecting tzlocal<5,>=1.1\n",
      "  Using cached tzlocal-4.3.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in e:\\anaconda\\lib\\site-packages (from streamlit) (4.11.3)\n",
      "Collecting pydeck<1,>=0.8\n",
      "  Using cached pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.1.0 in e:\\anaconda\\lib\\site-packages (from streamlit) (4.4.0)\n",
      "Requirement already satisfied: pillow<10,>=7.1.0 in e:\\anaconda\\lib\\site-packages (from streamlit) (9.4.0)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in e:\\anaconda\\lib\\site-packages (from streamlit) (2.1.6)\n",
      "Requirement already satisfied: click<9,>=7.0 in e:\\anaconda\\lib\\site-packages (from streamlit) (8.0.4)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in e:\\anaconda\\lib\\site-packages (from streamlit) (1.5.3)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in e:\\anaconda\\lib\\site-packages (from streamlit) (22.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in e:\\anaconda\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Collecting blinker<2,>=1.0.0\n",
      "  Using cached blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in e:\\anaconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.17.3)\n",
      "Requirement already satisfied: jinja2 in e:\\anaconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: toolz in e:\\anaconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in e:\\anaconda\\lib\\site-packages (from importlib-metadata<7,>=1.4->streamlit) (3.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in e:\\anaconda\\lib\\site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\lib\\site-packages (from requests<3,>=2.18->streamlit) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\anaconda\\lib\\site-packages (from requests<3,>=2.18->streamlit) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\lib\\site-packages (from requests<3,>=2.18->streamlit) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda\\lib\\site-packages (from requests<3,>=2.18->streamlit) (1.26.14)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting tzdata\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Collecting pytz-deprecation-shim\n",
      "  Using cached pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\anaconda\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in e:\\anaconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in e:\\anaconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: validators, tzdata, tenacity, smmap, pympler, pygments, pyarrow, protobuf, mdurl, cachetools, blinker, pytz-deprecation-shim, pydeck, markdown-it-py, gitdb, tzlocal, rich, gitpython, altair, streamlit\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.0.1\n",
      "    Uninstalling tenacity-8.0.1:\n",
      "      Successfully uninstalled tenacity-8.0.1\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "Successfully installed altair-5.1.1 blinker-1.6.2 cachetools-5.3.1 gitdb-4.0.10 gitpython-3.1.36 markdown-it-py-3.0.0 mdurl-0.1.2 protobuf-4.24.3 pyarrow-13.0.0 pydeck-0.8.0 pygments-2.16.1 pympler-1.0.1 pytz-deprecation-shim-0.1.0.post0 rich-13.5.2 smmap-5.0.0 streamlit-1.26.0 tenacity-8.2.3 tzdata-2023.3 tzlocal-4.3.1 validators-0.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6619ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "from streamlit_option_menu import option_menu\n",
    "import mysql.connector as sql\n",
    "import pymongo\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8e135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING PAGE CONFIGURATIONS\n",
    "\n",
    "st.set_page_config(page_title= \"Youtube Data Harvesting and Warehousing \",\n",
    "                   \n",
    "                   layout= \"wide\",\n",
    "                   initial_sidebar_state= \"expanded\",\n",
    "                   menu_items={'About': \"\"\"# This app is analysis youtube channel\"\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING OPTION MENU\n",
    "with st.sidebar:\n",
    "    selected = option_menu(None, [\"Home\",\"Extract and Transform\",\"View\"], \n",
    "                           icons=[\"house-door-fill\",\"tools\",\"card-text\"],\n",
    "                           default_index=0,\n",
    "                           orientation=\"vertical\",\n",
    "                           styles={\"nav-link\": {\"font-size\": \"30px\", \"text-align\": \"centre\", \"margin\": \"0px\", \n",
    "                                                \"--hover-color\": \"#C80101\"},\n",
    "                                   \"icon\": {\"font-size\": \"30px\"},\n",
    "                                   \"container\" : {\"max-width\": \"6000px\"},\n",
    "                                   \"nav-link-selected\": {\"background-color\": \"#C80101\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2480572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bridging a connection with MongoDB Atlas and Creating a new database(youtube_data)\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client['youtube_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ae568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONNECTING WITH MYSQL DATABASE\n",
    "mydb = sql.connect(host=\"localhost\",\n",
    "                   user=\"root\",\n",
    "                   password=\"1234567890\",\n",
    "                   database= \"youtube_db\"\n",
    "                  )\n",
    "mycursor = mydb.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789414f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING CONNECTION WITH YOUTUBE API\n",
    "api_key = \"AIzaSyCgiK4HggK4AI7N6hbyyiEIS9f3-EKHjVg\"\n",
    "youtube = build('youtube','v3',developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dcb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO GET CHANNEL DETAILS\n",
    "def get_channel_details(channel_id):\n",
    "    ch_data = []\n",
    "    response = youtube.channels().list(part = 'snippet,contentDetails,statistics',\n",
    "                                     id= channel_id).execute()\n",
    "\n",
    "    for i in range(len(response['items'])):\n",
    "        data = dict(Channel_id = channel_id[i],\n",
    "                    Channel_name = response['items'][i]['snippet']['title'],\n",
    "                    Playlist_id = response['items'][i]['contentDetails']['relatedPlaylists']['uploads'],\n",
    "                    Subscribers = response['items'][i]['statistics']['subscriberCount'],\n",
    "                    Views = response['items'][i]['statistics']['viewCount'],\n",
    "                    Total_videos = response['items'][i]['statistics']['videoCount'],\n",
    "                    Description = response['items'][i]['snippet']['description'],\n",
    "                    Country = response['items'][i]['snippet'].get('country')\n",
    "                    )\n",
    "        ch_data.append(data)\n",
    "    return ch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bebe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO GET VIDEO IDS\n",
    "def get_channel_videos(channel_id):\n",
    "    video_ids = []\n",
    "    # get Uploads playlist id\n",
    "    res = youtube.channels().list(id=channel_id, \n",
    "                                  part='contentDetails').execute()\n",
    "    playlist_id = res['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    next_page_token = None\n",
    "    \n",
    "    while True:\n",
    "        res = youtube.playlistItems().list(playlistId=playlist_id, \n",
    "                                           part='snippet', \n",
    "                                           maxResults=50,\n",
    "                                           pageToken=next_page_token).execute()\n",
    "        \n",
    "        for i in range(len(res['items'])):\n",
    "            video_ids.append(res['items'][i]['snippet']['resourceId']['videoId'])\n",
    "        next_page_token = res.get('nextPageToken')\n",
    "        \n",
    "        if next_page_token is None:\n",
    "            break\n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO GET VIDEO DETAILS\n",
    "def get_video_details(v_ids):\n",
    "    video_stats = []\n",
    "    \n",
    "    for i in range(0, len(v_ids), 50):\n",
    "        response = youtube.videos().list(\n",
    "                    part=\"snippet,contentDetails,statistics\",\n",
    "                    id=','.join(v_ids[i:i+50])).execute()\n",
    "        for video in response['items']:\n",
    "            video_details = dict(Channel_name = video['snippet']['channelTitle'],\n",
    "                                Channel_id = video['snippet']['channelId'],\n",
    "                                Video_id = video['id'],\n",
    "                                Title = video['snippet']['title'],\n",
    "                                Tags = video['snippet'].get('tags'),\n",
    "                                Thumbnail = video['snippet']['thumbnails']['default']['url'],\n",
    "                                Description = video['snippet']['description'],\n",
    "                                Published_date = video['snippet']['publishedAt'],\n",
    "                                Duration = video['contentDetails']['duration'],\n",
    "                                Views = video['statistics']['viewCount'],\n",
    "                                Likes = video['statistics'].get('likeCount'),\n",
    "                                Comments = video['statistics'].get('commentCount'),\n",
    "                                Favorite_count = video['statistics']['favoriteCount'],\n",
    "                                Definition = video['contentDetails']['definition'],\n",
    "                                Caption_status = video['contentDetails']['caption']\n",
    "                               )\n",
    "            video_stats.append(video_details)\n",
    "    return video_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f6790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO GET COMMENT DETAILS\n",
    "def get_comments_details(v_id):\n",
    "    comment_data = []\n",
    "    try:\n",
    "        next_page_token = None\n",
    "        while True:\n",
    "            response = youtube.commentThreads().list(part=\"snippet,replies\",\n",
    "                                                    videoId=v_id,\n",
    "                                                    maxResults=100,\n",
    "                                                    pageToken=next_page_token).execute()\n",
    "            for cmt in response['items']:\n",
    "                data = dict(Comment_id = cmt['id'],\n",
    "                            Video_id = cmt['snippet']['videoId'],\n",
    "                            Comment_text = cmt['snippet']['topLevelComment']['snippet']['textDisplay'],\n",
    "                            Comment_author = cmt['snippet']['topLevelComment']['snippet']['authorDisplayName'],\n",
    "                            Comment_posted_date = cmt['snippet']['topLevelComment']['snippet']['publishedAt'],\n",
    "                            Like_count = cmt['snippet']['topLevelComment']['snippet']['likeCount'],\n",
    "                            Reply_count = cmt['snippet']['totalReplyCount']\n",
    "                           )\n",
    "                comment_data.append(data)\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            if next_page_token is None:\n",
    "                break\n",
    "    except:\n",
    "        pass\n",
    "    return comment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5f75d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO GET CHANNEL NAMES FROM MONGODB\n",
    "def channel_names():   \n",
    "    ch_name = []\n",
    "    for i in db.channel_details.find():\n",
    "        ch_name.append(i['Channel_name'])\n",
    "    return ch_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b4464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOME PAGE\n",
    "if selected == \"Home\":\n",
    "    # Title Image\n",
    "    \n",
    "    col1,col2 = st.columns(2,gap= 'medium')\n",
    "    col1.markdown(\"## :blue[Domain] : Social Media\")\n",
    "    col1.markdown(\"## :blue[Technologies used] : Python,MongoDB, Youtube Data API, MySql, Streamlit\")\n",
    "    col1.markdown(\"## :blue[Overview] : Retrieving the Youtube channels data from the Google API, storing it in a MongoDB as data lake, migrating and transforming data into a SQL database,then querying the data and displaying it in the Streamlit app.\")\n",
    "    col2.markdown(\"#   \")\n",
    "    col2.markdown(\"#   \")\n",
    "    col2.markdown(\"#   \")\n",
    "    col2.image(\"youtubeMain.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT and TRANSFORM PAGE\n",
    "if selected == \"Extract and Transform\":\n",
    "    tab1,tab2 = st.tabs([\"$\\huge EXTRACT $\", \"$\\huge TRANSFORM $\"])\n",
    "    \n",
    "    # EXTRACT TAB\n",
    "    with tab1:\n",
    "        st.markdown(\"#    \")\n",
    "        st.write(\"### Enter YouTube Channel_ID below :\")\n",
    "        ch_id = st.text_input(\"Hint : Goto channel's home page > Right click > View page source > Find channel_id\").split(',')\n",
    "\n",
    "        if ch_id and st.button(\"Extract Data\"):\n",
    "            ch_details = get_channel_details(ch_id)\n",
    "            st.write(f'#### Extracted data from :green[\"{ch_details[0][\"Channel_name\"]}\"] channel')\n",
    "            st.table(ch_details)\n",
    "\n",
    "        if st.button(\"Upload to MongoDB\"):\n",
    "            with st.spinner('Please Wait for it...'):\n",
    "                ch_details = get_channel_details(ch_id)\n",
    "                v_ids = get_channel_videos(ch_id)\n",
    "                vid_details = get_video_details(v_ids)\n",
    "                \n",
    "                def comments():\n",
    "                    com_d = []\n",
    "                    for i in v_ids:\n",
    "                        com_d+= get_comments_details(i)\n",
    "                    return com_d\n",
    "                comm_details = comments()\n",
    "\n",
    "                collections1 = db.channel_details\n",
    "                collections1.insert_many(ch_details)\n",
    "\n",
    "                collections2 = db.video_details\n",
    "                collections2.insert_many(vid_details)\n",
    "\n",
    "                collections3 = db.comments_details\n",
    "                collections3.insert_many(comm_details)\n",
    "                st.success(\"Upload to MogoDB successful !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb5b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORM TAB\n",
    "    with tab2:     \n",
    "        st.markdown(\"#   \")\n",
    "        st.markdown(\"### Select a channel to begin Transformation to SQL\")\n",
    "        \n",
    "        ch_names = channel_names()\n",
    "        user_inp = st.selectbox(\"Select channel\",options= ch_names)\n",
    "        \n",
    "        def insert_into_channels():\n",
    "                collections = db.channel_details\n",
    "                query = \"\"\"INSERT INTO channels VALUES(%s,%s,%s,%s,%s,%s,%s,%s)\"\"\"\n",
    "                \n",
    "                for i in collections.find({\"Channel_name\" : user_inp},{'_id':0}):\n",
    "                    mycursor.execute(query,tuple(i.values()))\n",
    "                    mydb.commit()\n",
    "                \n",
    "        def insert_into_videos():\n",
    "            collectionss = db.video_details\n",
    "            query1 = \"\"\"INSERT INTO videos VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\"\"\n",
    "\n",
    "            for i in collectionss.find({\"Channel_name\" : user_inp},{\"_id\":0}):\n",
    "                t=tuple(i.values())\n",
    "                mycursor.execute(query1,t)\n",
    "                mydb.commit()\n",
    "\n",
    "        def insert_into_comments():\n",
    "            collections1 = db.video_details\n",
    "            collections2 = db.comments_details\n",
    "            query2 = \"\"\"INSERT INTO comments VALUES(%s,%s,%s,%s,%s,%s,%s)\"\"\"\n",
    "\n",
    "            for vid in collections1.find({\"Channel_name\" : user_inp},{'_id' : 0}):\n",
    "                for i in collections2.find({'Video_id': vid['Video_id']},{'_id' : 0}):\n",
    "                    t=tuple(i.values())\n",
    "                    mycursor.execute(query2,t)\n",
    "                    mydb.commit()\n",
    "\n",
    "        if st.button(\"Submit\"):\n",
    "            try:\n",
    "                \n",
    "                insert_into_channels()\n",
    "                insert_into_videos()\n",
    "                insert_into_comments()\n",
    "                st.success(\"Transformation to MySQL Successful!!!\")\n",
    "            except:\n",
    "                st.error(\"Channel details already transformed!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315cde2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIEW PAGE\n",
    "if selected == \"View\":\n",
    "    \n",
    "    st.write(\"## :orange[Select any question to get Insights]\")\n",
    "    questions = st.selectbox('Questions',\n",
    "    ['Click the question that you would like to query',\n",
    "    '1. What are the names of all the videos and their corresponding channels?',\n",
    "    '2. Which channels have the most number of videos, and how many videos do they have?',\n",
    "    '3. What are the top 10 most viewed videos and their respective channels?',\n",
    "    '4. How many comments were made on each video, and what are their corresponding video names?',\n",
    "    '5. Which videos have the highest number of likes, and what are their corresponding channel names?',\n",
    "    '6. What is the total number of likes and dislikes for each video, and what are their corresponding video names?',\n",
    "    '7. What is the total number of views for each channel, and what are their corresponding channel names?',\n",
    "    '8. What are the names of all the channels that have published videos in the year 2022?',\n",
    "    '9. What is the average duration of all videos in each channel, and what are their corresponding channel names?',\n",
    "    '10. Which videos have the highest number of comments, and what are their corresponding channel names?'])\n",
    "    \n",
    "    if questions == '1. What are the names of all the videos and their corresponding channels?':\n",
    "        mycursor.execute(\"\"\"SELECT title AS Video_Title, channel_name AS Channel_Name FROM videos ORDER BY channel_name\"\"\")\n",
    "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
    "        st.write(df)\n",
    "        \n",
    "    elif questions == '2. Which channels have the most number of videos, and how many videos do they have?':\n",
    "        mycursor.execute(\"\"\"SELECT channel_name \n",
    "        AS Channel_Name, total_videos AS Total_Videos\n",
    "                            FROM channels\n",
    "                            ORDER BY total_videos DESC\"\"\")\n",
    "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
    "        st.write(df)\n",
    "        st.write(\"### :green[Number of videos in each channel :]\")\n",
    "        #st.bar_chart(df,x= mycursor.column_names[0],y= mycursor.column_names[1])\n",
    "        fig = px.bar(df,\n",
    "                     x=mycursor.column_names[0],\n",
    "                     y=mycursor.column_names[1],\n",
    "                     orientation='v',\n",
    "                     color=mycursor.column_names[0]\n",
    "                    )\n",
    "        st.plotly_chart(fig,use_container_width=True)\n",
    "        \n",
    "    elif questions == '3. What are the top 10 most viewed videos and their respective channels?':\n",
    "        mycursor.execute(\"\"\"SELECT channel_name AS Channel_Name, title AS Video_Title, views AS Views \n",
    "                            FROM videos\n",
    "                            ORDER BY views DESC\n",
    "                            LIMIT 10\"\"\")\n",
    "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
    "        st.write(df)\n",
    "        st.write(\"### :green[Top 10 most viewed videos :]\")\n",
    "        fig = px.bar(df,\n",
    "                     x=mycursor.column_names[2],\n",
    "                     y=mycursor.column_names[1],\n",
    "                     orientation='h',\n",
    "                     color=mycursor.column_names[0]\n",
    "                    )\n",
    "        st.plotly_chart(fig,use_container_width=True)\n",
    "        \n",
    "    elif questions == '4. How many comments were made on each video, and what are their corresponding video names?':\n",
    "        mycursor.execute(\"\"\"SELECT a.video_id AS Video_id, a.title AS Video_Title, b.Total_Comments\n",
    "                            FROM videos AS a\n",
    "                            LEFT JOIN (SELECT video_id,COUNT(comment_id) AS Total_Comments\n",
    "                            FROM comments GROUP BY video_id) AS b\n",
    "                            ON a.video_id = b.video_id\n",
    "                            ORDER BY b.Total_Comments DESC\"\"\")\n",
    "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
    "        st.write(df)\n",
    "          \n",
    "    elif questions == '5. Which videos have the highest number of likes, and what are their corresponding channel names?':\n",
    "        mycursor.execute(\"\"\"SELECT channel_name AS Channel_Name,title AS Title,likes AS Likes_Count \n",
    "                            FROM videos\n",
    "                            ORDER BY likes DESC\n",
    "                            LIMIT 10\"\"\")\n",
    "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
    "        st.write(df)\n",
    "        st.write(\"### :green[Top 10 most liked videos :]\")\n",
    "        fig = px.bar(df,\n",
    "                     x=mycursor.column_names[2],\n",
    "                     y=mycursor.column_names[1],\n",
    "                     orientation='h',\n",
    "                     color=mycursor.column_names[0]\n",
    "                    )\n",
    "        st.plotly_chart(fig,use_container_width=True)\n",
    "        \n",
    "    elif questions == '6. What is the total number of likes and dislikes for each video, and what are their corresponding video names?':\n",
    "        mycursor.execute(\"\"\"SELECT title AS Title, likes AS Likes_Count\n",
    "                            FROM videos\n",
    "                            ORDER BY likes DESC\"\"\")\n",
    "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
    "        st.write(df)\n",
    "         \n",
    "    elif questions == '7. What is the total number of views for each channel, and what are their corresponding channel names?':\n",
    "        mycursor.execute(\"\"\"SELECT channel_name AS Channel_Name, views AS Views\n",
    "                            FROM channels\n",
    "                            ORDER BY views DESC\"\"\")\n",
    "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
    "        st.write(df)\n",
    "        st.write(\"### :green[Channels vs Views :]\")\n",
    "        fig = px.bar(df,\n",
    "                     x=mycursor.column_names[0],\n",
    "                     y=mycursor.column_names[1],\n",
    "                     orientation='v',\n",
    "                     color=mycursor.column_names[0]\n",
    "                    )\n",
    "        st.plotly_chart(fig,use_container_width=True)\n",
    "        \n",
    "    elif questions == '8. What are the names of all the channels that have published videos in the year 2022?':\n",
    "        mycursor.execute(\"\"\"SELECT channel_name AS Channel_Name\n",
    "                            FROM videos\n",
    "                            WHERE published_date LIKE '2022%'\n",
    "                            GROUP BY channel_name\n",
    "                            ORDER BY channel_name\"\"\")\n",
    "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
    "        st.write(df)\n",
    "        \n",
    "    elif questions == '9. What is the average duration of all videos in each channel, and what are their corresponding channel names?':\n",
    "        mycursor.execute(\"\"\"SELECT channel_name AS Channel_Name,\n",
    "                            AVG(duration)/60 AS \"Average_Video_Duration (mins)\"\n",
    "                            FROM videos\n",
    "                            GROUP BY channel_name\n",
    "                            ORDER BY AVG(duration)/60 DESC\"\"\")\n",
    "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
    "        st.write(df)\n",
    "        st.write(\"### :green[Avg video duration for channels :]\")\n",
    "        fig = px.bar(df,\n",
    "                     x=mycursor.column_names[0],\n",
    "                     y=mycursor.column_names[1],\n",
    "                     orientation='v',\n",
    "                     color=mycursor.column_names[0]\n",
    "                    )\n",
    "        st.plotly_chart(fig,use_container_width=True)\n",
    "        \n",
    "    elif questions == '10. Which videos have the highest number of comments, and what are their corresponding channel names?':\n",
    "        mycursor.execute(\"\"\"SELECT channel_name AS Channel_Name,video_id AS Video_ID,comments AS Comments\n",
    "                            FROM videos\n",
    "                            ORDER BY comments DESC\n",
    "                            LIMIT 10\"\"\")\n",
    "        df = pd.DataFrame(mycursor.fetchall(),columns=mycursor.column_names)\n",
    "        st.write(df)\n",
    "        st.write(\"### :green[Videos with most comments :]\")\n",
    "        fig = px.bar(df,\n",
    "                     x=mycursor.column_names[1],\n",
    "                     y=mycursor.column_names[2],\n",
    "                     orientation='v',\n",
    "                     color=mycursor.column_names[0]\n",
    "                    )\n",
    "        st.plotly_chart(fig,use_container_width=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
